{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"/Users/Bruger/Desktop/Social Data Visualizations/socialdata2024/Police_Department_Incident_Reports__Historical_2003_to_May_2018_20240204.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "\n",
    "df.head()\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the year\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
    "# Remove 2018 as this year is not complete\n",
    "df = df[df['Date'].dt.year != 2018]\n",
    "df['Year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCategories = df[\"Category\"].unique()\n",
    "\n",
    "# Calculate the number of rows\n",
    "nrows = math.ceil(len(NCategories) / 2)\n",
    "\n",
    "fig = make_subplots(rows=nrows, cols=2, subplot_titles=NCategories)\n",
    "\n",
    "for i, category in enumerate(NCategories, start=1):\n",
    "    category_df = df[df['Category'] == category]\n",
    "    bar_data = category_df['Year'].value_counts().reset_index()\n",
    "    bar = go.Bar(x=bar_data['index'], y=bar_data['Year'], name=category)\n",
    "    fig.add_trace(bar, row=(i+1)//2, col=i%2+1)\n",
    "\n",
    "fig.update_layout(height=300*nrows, showlegend=False)\n",
    "for i in range(1, len(NCategories) + 1):\n",
    "    fig.update_xaxes(title_text=\"Year\", row=(i+1)//2, col=i%2+1)\n",
    "    fig.update_yaxes(title_text=\"Occurrences\", row=(i+1)//2, col=i%2+1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look at forgery/counterfeiting. Because this category seems to be decreasing rapidly in recent years. This could be due to the fact that documents are being digitalized more and more and therefore, these are not as easily forged as they were in the past. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a map of SF to show where the forgery/counterfeiting takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomdata = {\n",
    "    'CENTRAL': 0.283805288999638,\n",
    "    'SOUTHERN': 0.8882636532075772,\n",
    "    'BAYVIEW': 0.45059924801053985,\n",
    "    'MISSION': 0.6000904430914474,\n",
    "    'PARK': 0.6362552416309091,\n",
    "    'RICHMOND': 0.3371857964893169,\n",
    "    'INGLESIDE': 0.09876749056377487,\n",
    "    'TARAVAL': 0.009436215026031758,\n",
    "    'NORTHERN': 0.44884916837512767,\n",
    "    'TENDERLOIN': 0.06616710190569974\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/suneman/socialdata2022/main/files/sfpd.geojson\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Ensure the request was successful\n",
    "if response.status_code == 200:\n",
    "    with open(\"sfpd.geojson\", 'wb') as f:\n",
    "        f.write(response.content)\n",
    "else:\n",
    "    print(\"Failed to download the file.\")\n",
    "\n",
    "# Open the GeoJSON file and load it into a GeoJSON object\n",
    "with open(\"sfpd.geojson\") as f:\n",
    "    geojson = json.load(f)\n",
    "\n",
    "# Convert your GeoJSON object to a DataFrame\n",
    "dfgeo = pd.json_normalize(geojson['features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crime category\n",
    "forgery = df[df['Category'] == 'FORGERY/COUNTERFEITING']\n",
    "\n",
    "# Aggregate data by police district\n",
    "district_df = forgery.groupby(['PdDistrict'])['Category'].count()\n",
    "district_df = district_df.to_frame()\n",
    "district_df.reset_index(inplace=True)\n",
    "district_df.rename(columns={'PdDistrict': 'Count'}, inplace=True)\n",
    "print(district_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth_mapbox(district_df, geojson=geojson, locations='Count', color='Category',\n",
    "                           color_continuous_scale=\"Bluered\",\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=11, center = {\"lat\": 37.77, \"lon\": -122.4},\n",
    "                           opacity=0.5,\n",
    "                           labels={'PdDistrict':'District'}\n",
    "                          )\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the most forgeries take place in the Southern district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a HeatMapWithTime for 'FORGERY/COUNTERFEITING'\n",
    "from folium.plugins import HeatMapWithTime\n",
    "\n",
    "# Delete rows where location is nan\n",
    "df = df.dropna(subset=['X', 'Y', 'Time'])\n",
    "\n",
    "# Convert 'Time' column to datetime format\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Group by year and month\n",
    "df['YearMonth'] = df['Time'].dt.to_period('M')\n",
    "\n",
    "# Filter 'BAD CHECKS' category\n",
    "forgery_df = df[df['Category'] == 'FORGERY/COUNTERFEITING']\n",
    "\n",
    "# Prepare data for HeatMapWithTime\n",
    "data = [\n",
    "    [[row['Y'], row['X']] for index, row in forgery_df[forgery_df['YearMonth'] == t].iterrows()]\n",
    "    for t in forgery_df['YearMonth'].sort_values().unique()\n",
    "]\n",
    "\n",
    "# Create map\n",
    "m = folium.Map([forgery_df['Y'].mean(), forgery_df['X'].mean()], zoom_start=13)\n",
    "\n",
    "# Create HeatMapWithTime and add it to the map\n",
    "hmwt = HeatMapWithTime(data)\n",
    "hmwt.add_to(m)\n",
    "\n",
    "# Display map\n",
    "m\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
